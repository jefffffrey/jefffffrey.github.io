{"meta":{"title":"Jeffrey's Blog","subtitle":"Live and learn!","description":null,"author":"Jeffrey Teo","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2017-10-28T10:43:33.000Z","updated":"2017-10-28T10:43:33.252Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"OpenCV 表格文字识别","slug":"OpenCV-表格文字识别","date":"2017-11-15T10:38:36.000Z","updated":"2017-11-15T10:46:34.572Z","comments":true,"path":"2017/11/15/OpenCV-表格文字识别/","link":"","permalink":"http://yoursite.com/2017/11/15/OpenCV-表格文字识别/","excerpt":"","text":"最近项目需要识别图片中的表格文字，遂学习了一波OpenCV。现在将整个流程记录下来以供交流和分享。 本次的目标是识别下图中的表格，最终需要知道每一部分填写的内容内容是什么，比如知道用户电话是13988881234。我将此次任务划分为3个步骤： 识别出每一个单元格，得到其矩形区域的位置 知道每一个矩形区域的意义。比如知道e矩形区域代表用户的电话号码 对该区域的图片进行文字识别 本文将要讲解的就是如何完成第一步：得到所有矩形区域的位置。其余步骤可能会在之后的文章进行讲解。我采用的语言是Python，即使你不懂Python也应该能看懂流程，因为Python非常易读。我采用的OpenCV为当前的最新版3.3.1。 如果你是Linux用户且需要安装OpenCV及其相关的Python库，请看我的另一篇文章：Linux OpenCV安装指南 原理我们知道OpenCV提供了轮廓识别的API：findContours，根据该API的描述，在轮廓检测之前，首先要对图片进行二值化或者Canny边缘检测。寻找的物体是白色的，而背景必须是黑色的。 经过测试后使用二值化的方式对图片进行处理比较好，要注意的是调用threshold时的阈值方法要使用THRESH_BINARY_INV（因为我们需要变成白色，背景变成黑色）。 其次经过二值化处理之后我发现有些边框会出现一些小的空隙，可能是打印问题或者其他因素造成的。对于这种细小的空隙我采用对二值化后的图片进行一次膨胀操作进行去除。 最后一步就是检测轮廓，使用findContours方法，并且轮廓检索模式（Contour retrieval mode）使用RETR_TREE，使用模式我们不仅可以得到所有的轮廓，同时还可以得到轮廓之间的关系（父子关系，兄弟关系）检测出所有轮廓之后，我们需要找出其中最大的轮廓，它代表表格的外边框，然后其所有的子轮廓就是我们要找的内容。 这一步遇到的问题是OpenCV会识别出多余的轮廓，或者识别出的轮廓形状不像长方形。为了防止识别出的多余的轮廓，我们采用面积过滤，估算一下表格中最小的单元格区域的面积，然后所有小于该面积的都过滤掉。对于轮廓不像长方形，我们采用boundingRect得到包含该区域的最小矩形。 代码# -*- coding: utf-8 -*-import numpy as npimport cv2img = cv2.imread('1.jpg')# 灰度图gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)# 阈值_, threshold = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)# 膨胀kernel = np.ones((3, 3), np.uint8)dilated = cv2.dilate(threshold, kernel, iterations=1)# 轮廓检测_, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)# 找到表格最外层轮廓tree = hierarchy[0]max_size = 0outer_contour_index = Nonefor i, contour in enumerate(contours): size = cv2.contourArea(contour) if size &gt; max_size: max_size = size outer_contour_index = icontour = contours[outer_contour_index]# 估算最小的单元格大小x, y, w, h = cv2.boundingRect(contour)cell_size = w * h * 0.0015# 遍历所有最外层轮廓的子轮廓，过滤掉面积小于cell_size的，然后全部用矩形标注起来contour_index = tree[outer_contour_index][2]count = 0while 1: contour = contours[contour_index] if cv2.contourArea(contour) &gt; cell_size: x, y, w, h = cv2.boundingRect(contour) count += 1 cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 3) contour_index = tree[contour_index][0] if contour_index &lt; 0: cv2.imwrite('11.jpg', img) break 效果图 参考链接 Image Processing (imgproc module)","categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"图像处理","slug":"CS/图像处理","permalink":"http://yoursite.com/categories/CS/图像处理/"}],"tags":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/tags/CS/"},{"name":"图像处理","slug":"图像处理","permalink":"http://yoursite.com/tags/图像处理/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/tags/OpenCV/"}]},{"title":"Linux OpenCV安装指南","slug":"Linux-OpenCV安装指南","date":"2017-11-09T06:12:15.000Z","updated":"2017-11-15T10:53:53.061Z","comments":true,"path":"2017/11/09/Linux-OpenCV安装指南/","link":"","permalink":"http://yoursite.com/2017/11/09/Linux-OpenCV安装指南/","excerpt":"","text":"本教程是笔者在Linux Mint 16.1（基于Ubuntu 16.04）下测试后给出的指南，理论情况下也适用于其他发行版。 安装依赖[compiler] sudo apt-get install build-essential[required] sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev[optional] sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev libgtk2.0-dev依赖问题安装过程中可能出现如下问题： 下列软件包有未满足的依赖关系： libgtk2.0-dev : 依赖: libgdk-pixbuf2.0-dev (&gt;= 2.21.0) 但是它将不会被安装 依赖: libpango1.0-dev (&gt;= 1.20) 但是它将不会被安装 依赖: libcairo2-dev (&gt;= 1.6.4-6.1) 但是它将不会被安装 如果出现此问题，则以此执行下列命令即可： sudo apt install libpng12-0=1.2.54-1ubuntu1sudo apt-get install libpng12-dev sudo apt-get install libgdk-pixbuf2.0-dev sudo apt-get install libgtk2.0-dev 安装OpenCV下载源码到该页面下载需要的版本：https://opencv.org/releases.html 编译安装cd opencv-*mkdir buildcd buildcmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local .. 如果cmake过程中出现了下面这个问题： CMake Error at CMakeLists.txt:11 (message): FATAL: In-source builds are not allowed. You should create a separate directory for build files.-- Configuring incomplete, errors occurred! 删除掉opencv-**目录下的CMakeCache.txt*，之后在执行安装即可。 安装Python包另外要使用Python调用OpenCV需要安装的python-opencv包: sudo apt-get install python-opencv 参考链接 http://blog.csdn.net/FogXcG/article/details/75808783 https://docs.opencv.org/master/d7/d9f/tutorial_linux_install.html https://stackoverflow.com/questions/45518317/in-source-builds-are-not-allowed-in-cmake","categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"图像处理","slug":"CS/图像处理","permalink":"http://yoursite.com/categories/CS/图像处理/"}],"tags":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/tags/CS/"},{"name":"图像处理","slug":"图像处理","permalink":"http://yoursite.com/tags/图像处理/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/tags/OpenCV/"}]},{"title":"统计机器翻译（SMT）简介","slug":"统计机器翻译（SMT）简介","date":"2017-11-08T06:56:34.000Z","updated":"2017-11-08T08:57:10.122Z","comments":true,"path":"2017/11/08/统计机器翻译（SMT）简介/","link":"","permalink":"http://yoursite.com/2017/11/08/统计机器翻译（SMT）简介/","excerpt":"","text":"统计机器翻译（英语：Statistical Machine Translation，简写为SMT）是机器翻译的一种，基本思想是通过对大量的平行语料进行统计分析，构建模型，进而使用此模型进行翻译。 所谓的平行语料就是表达同一个意思的不同语言的句子，如： 這是一個蘋果。This is an apple.桌上有一本書。There is a book on the table． 模型的定义假设一个源语言句子$f$和一个目标语言句子$e$，我们定义$f$翻译成$e$的概率为：$$p(e|f)$$于是如何将$f$翻译成$e$的问题就变成了求解$p(e|f)$最大的时候的$e$。由贝叶斯定理可知:$$p(e \\mid f) = \\frac{p(f \\mid e)p(e)}{p(f)}$$由于$f$句子是已知的，所以$p(f)$是一个常数，因此求解$p(e|f)$最大的时候的$e$就是求解$p(f \\mid e)p(e)$最大的时候的$e$。用公式表示就是：$$\\mathop{\\arg\\,\\max}\\limits{e} p(e \\mid f) = \\mathop{\\arg\\,\\max}\\limits{e} p(e)\\times p(f \\mid e)$$ 举个例子，假设要将“我肚子饿了”翻译，并且我们已经根据模型计算出了可能翻译的句子，如下：$$\\begin{array}{c | c c}English &amp; p(f \\mid e) &amp; p (e) \\ \\hline\\text{I am hungry} &amp; 0.00019 &amp; 0.0084\\\\text{My belly hungry} &amp; 0.00031 &amp; 0.0000031\\\\text{I starve} &amp; 0.00045 &amp; 0.0000012\\\\end{array}$$ 那么这句中文最有可能的翻译则为“I am hungry”。因为它的$ p(e)\\times p(f \\mid e)$最大。在统计机器翻译中，我们把$ p(e)$叫做语言模型，表示一个句子是一个流畅的句子的概率，比如上面“I am hungry”就比另外两个流程;我们把$ p(f \\mid e)$叫做翻译模型，表示把句子从$e$翻译到$f$的概率。从中国对翻译的传统要求“信达雅”三点上看，翻译模型体现了信与达，而雅则在语言模型中得到反映。 因此我们的主要任务就是训练模型，让它知道各种情况下$ p(f \\mid e)$的值和$ p(e)$的值。 语言模型假如$e$这个句子由$w1$，$w2$…$wn$这些单词组成的，那么可知：$$p(e)=p(w1)p(w2|w1)p(w3|w1,w2)…p(wn|w1,w2,…,wn-1)$$即：$e$这个句子出现的概率等于第一个单词出现的概率$\\times$第一个单词出现的情况下第二个单词出现的概率$\\times$第一个单词和第二个单词均出现的情况下第三个单词出现的概率… 而以上的各个单词在其前面的单词出现的情况下出现的概率是可以通过语料库统计出来的。这里就解决了$p(e)$计算的问题。 随着句子单词数量增多，$p(wn|w1,w2,…,wn-1)$计算将会变得非常耗时，所以一般实际中采取n-gram求近似值。n一般不超过3, google使用的是4. 翻译模型我们假设$e$由$(e1,e2…,el)$这些单词按顺序组成，$f$由$(f1,f2,…,fj)$这些单词按照顺序组成：那么$p(f \\mid e)$这个问题可以看成$(e1,e2…,el)$到$(f1,f2,…,fj)$的概率问题。第一个句子如何转换为第二个句子呢，我们假设这之间存在一种转换A，那么:$$P(F\\mid E) = \\sum{A} P(F,A \\mid E) = \\sum{A} P(F \\mid E, A) \\times P(A \\mid E)$$现在我们假设这种转换A就是$e$中的一个单词$el$到$f$中的一个单词$fj$的对齐转换。我们规定$e$中的每个单词可以对应$f$中的0-1个单词（因为有的$f$中的词可能在$e$中不存在，比如中文的”的”在英文中就找不到对应的单词），那么有：$$P(F \\mid E, A) = \\prod{j=1}^{J} t(f{j} \\mid e{A{j}})$$其中，$t(fj∣eAj)$ 表示在 alignment A 之下，对应到$fj$位置的$ej$ ，翻譯成 $fj$ 的機率。因为两个句子之间的对齐关系有很多种，现在我们假设每种对齐的概率都一样，那么：$$P(A \\mid E) = \\frac{\\epsilon}{(I+1)^{J}}$$将这两项代人原来的公式得到（这就是IBM Model 1）：$$\\begin{equation} P(F\\mid E) = \\sum{A} P(F,A \\mid E) = \\sum{A} P(F \\mid E, A) \\times P(A \\mid E) \\ = \\sum{A} \\prod{j=1}^{J} t(f{j} \\mid e{A_{j}}) \\times \\frac{\\epsilon}{(I+1)^{J}} \\\\end{equation}$$我们只需要先求出该公式里面的各个参数，就可以使用该模型来进行翻译了。求解其中参数的问题这里就不描述了，感兴趣的可以去看一些$EF$算法。另外，$IBM Model 2$在$1$的基础上去掉所有对齐概率相等的假设并加入了新的参数：词在句子中的位置，$HMM$模型将$IBM Model 2$中的绝对位置更改为相对位置，即相对上一个词连接的位置，而IBM Model 3,4,5及Model 6引入了“Fertility Model”，代表一个词翻译为若干词的概率。 参考链接 机器翻译 – Statistical Machine Translation - MARK CHANG’S BLOG 机器翻译 – IBM Model 1 - MARK CHANG’S BLOG n元语法 - 维基百科 统计机器翻译 - 维基百科 基于词的统计机器翻译方法 - 中国科学院计算技术研究所 2010 年秋季课程","categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"自然语言处理","slug":"CS/自然语言处理","permalink":"http://yoursite.com/categories/CS/自然语言处理/"}],"tags":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/tags/CS/"},{"name":"自然语言处理","slug":"自然语言处理","permalink":"http://yoursite.com/tags/自然语言处理/"},{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"}]},{"title":"【Redis实战】存储24小时内的操作历史","slug":"【Redis实战】存储24小时内的操作历史","date":"2017-11-03T03:58:23.000Z","updated":"2017-11-08T08:14:51.212Z","comments":true,"path":"2017/11/03/【Redis实战】存储24小时内的操作历史/","link":"","permalink":"http://yoursite.com/2017/11/03/【Redis实战】存储24小时内的操作历史/","excerpt":"","text":"分析与实现一个消息应用有如下需求： 需要保留用户最近24小时内的所有操作历史 需要频繁的显示最近的10条操作历史给用户 需要频繁的显示24小时内总操作次数 这是一个典型的适合应用Redis的情形。现在需要考虑的是如何具体实现，首先想到的是采用字典（哈希表）列表的方式实现，其中每一个哈希表存储操作内容和操作时间，同时包含一个过期时间。但是考虑到Redis支持设置键的过期时间，所以哈希表本身可以不用存储过期时间，而是在创建的时候设置好过期时间即可。 我们给操作历史列表取名为history,之后每当有新的操作发生的时候我们需要在列表中新增一项，同时创建一个新的哈希表： 127.0.0.1:6379&gt; RPUSH history operation:1(integer) 1127.0.0.1:6379&gt; HMSET operation:1 time 12:23 desc o1OK127.0.0.1:6379&gt; EXPIRE operation:1 30(integer) 1 这样，当需要统计总操作数或者需要显示最近的10条记录的时候，我们需要先遍历history列表，然后删除掉其中已经过期的哈希表的键，最后再返回总条数或者最近10条记录。 为了减少网络传输时间，我们将删除过期键的功能使用Lua脚本实现并加载到Redis(&gt;2.6.0)中。Lua脚本： while (true)do if (redis.call('EXISTS', redis.call('LRANGE', KEYS[1], 0, 0)[1]) == 1) then break else if redis.call('LLEN', KEYS[1]) == 0 then break end redis.call('LPOP', KEYS[1]) endendlocal ret = &#123; 'ok' &#125;ret['ok'] = 'OK'return ret 查看本例完整的Python实现可访问Gist。 时间复杂度首先列出我们使用的各个操作的时间复杂度： 操作 时间复杂度 LPUSH O(1) HMSET O(N)， N 为 field-value 对的数量。 EXPIRE O(1) EXISTS O(1) LRANGE O(S+N)， S 为偏移量 start ， N 为指定区间内元素的数量。 LLEN O(1) LPOP O(1) 具体到我们实现的功能上来说，各个功能的时间复杂度如下： 功能 复杂度 新增一条操作记录 O(N)，N为hash中key的数量 删除过期的记录 O(N)，N为本次过期条数 取最新的10条记录 O(1) 参考链接避免误用 Redis Redis 命令参考 Redis Lua 脚本使用 Lua: A Guide for Redis Users How to Create and Expire List Items in Redis","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"},{"name":"Redis","slug":"数据库/Redis","permalink":"http://yoursite.com/categories/数据库/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"},{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"}]},{"title":"深入理解BFC和Margin Collapse","slug":"深入理解BFC和Margin-Collapse","date":"2017-11-01T14:19:05.000Z","updated":"2017-11-01T14:29:00.181Z","comments":true,"path":"2017/11/01/深入理解BFC和Margin-Collapse/","link":"","permalink":"http://yoursite.com/2017/11/01/深入理解BFC和Margin-Collapse/","excerpt":"","text":"BFC定义浮动元素和绝对定位元素，非块级盒子的块级容器（例如 inline-blocks, table-cells, 和 table-captions），以及overflow值不为“visiable”的块级盒子，都会为他们的内容创建新的BFC（块级格式上下文）。 在BFC中，盒子从顶端开始垂直地一个接一个地排列，两个盒子之间的垂直的间隙是由他们的margin 值所决定的。在一个BFC中，两个相邻的块级盒子的垂直外边距会产生塌陷。 在BFC中，每一个盒子的左外边缘（margin-left）会触碰到容器的左边缘(border-left)（对于从右到左的格式来说，则触碰到右边缘）。 Margin Collapse(外边距塌陷/外边距合并)在CSS当中，相邻的两个盒子（可能是兄弟关系也可能是祖先关系）的外边距可以结合成一个单独的外边距。这种合并外边距的方式被称为塌陷，并且因而所结合成的外边距称为塌陷外边距。 塌陷的结果 两个相邻的外边距都是正数时，塌陷结果是它们两者之间较大的值。 两个相邻的外边距都是负数时，塌陷结果是两者绝对值的较大值。 两个外边距一正一负时，塌陷结果是两者的相加的和。 产生塌陷的必备条件margin必须是邻接的，而根据w3c规范，两个margin是邻接的必须满足以下条件： 必须是处于常规文档流（非float和绝对定位）的块级盒子,并且处于同一个BFC当中。如果有元素脱离了常规文档流，那么该元素之后的元素和该元素之前的元素可以邻接。 没有线盒，没有空隙（clearance：当浮动元素之后的元素设置clear以闭合相关方向的浮动时会产生。有这个的时候，修改清除浮动元素的margin-top无效），没有padding和border将他们分隔开 都属于垂直方向上相邻的外边距，可以是下面任意一种情况 元素的margin-top与其第一个常规文档流的子元素的margin-top 元素的margin-bottom与其下一个常规文档流的兄弟元素的margin-top 元素的margin-bottom与其最后一个常规文档流的子元素的margin-bottom，同时元素的height设置为auto 高度为0并且最小高度也为0，不包含常规文档流的子元素，并且自身没有建立新的BFC的元素的margin-top和margin-bottom。 以上的条件意味着下列的规则： 创建了新的BFC的元素（例如浮动元素或者’overflow’值为’visible’以外的元素）与它的子元素的外边距不会塌陷 浮动元素不与任何元素的外边距产生塌陷（包括其父元素和子元素）。因为浮动元素产生新的BFC。 绝对定位元素不与任何元素的外边距产生塌陷 inline-block元素不与任何元素的外边距产生塌陷 一个常规文档流元素的margin-bottom与它下一个常规文档流的兄弟元素的margin-top会产生塌陷，除非它们之间存在间隙（clearance）。 一个常规文档流元素的margin-top 与其第一个常规文档流的子元素的margin-top产生塌陷，条件为父元素不包含 padding 和 border ，子元素不包含 clearance。 一个 ‘height’ 为 ‘auto’ 并且 ‘min-height’ 为 ‘0’的常规文档流元素的 margin-bottom 会与其最后一个常规文档流子元素的 margin-bottom 塌陷，条件为父元素不包含 padding 和 border ，子元素的 margin-bottom 不与包含 clearance 的 margin-top 塌陷。 一个不包含border-top、border-bottom、padding-top、padding-bottom的常规文档流元素，并且其 ‘height’ 为 0 或 ‘auto’， ‘min-height’ 为 ‘0’，其里面也不包含行盒(line box)，其自身的 margin-top 和 margin-bottom 会塌陷。 参考连接https://www.w3.org/TR/CSS22/box.html#collapsing-margins CSS: 深入理解BFC和Margin Collapse (margin叠加或者合并外边距) https://developer.mozilla.org/zh-CN/docs/Web/CSS/CSS_Box_Model/Mastering_margin_collapsing","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"},{"name":"CSS","slug":"前端/CSS","permalink":"http://yoursite.com/categories/前端/CSS/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"},{"name":"CSS","slug":"CSS","permalink":"http://yoursite.com/tags/CSS/"},{"name":"CSS盒模型","slug":"CSS盒模型","permalink":"http://yoursite.com/tags/CSS盒模型/"},{"name":"CSS布局","slug":"CSS布局","permalink":"http://yoursite.com/tags/CSS布局/"}]},{"title":"MySQL存储过程及函数核心知识点","slug":"MySQL存储过程及函数核心知识点","date":"2017-10-31T13:34:33.000Z","updated":"2017-11-03T04:23:37.866Z","comments":true,"path":"2017/10/31/MySQL存储过程及函数核心知识点/","link":"","permalink":"http://yoursite.com/2017/10/31/MySQL存储过程及函数核心知识点/","excerpt":"","text":"本文记录了MySQL存储过程的一些核心知识点，详细内容请参考官方文档。文中的MySQL版本为5.7。 语法CREATE [DEFINER = &#123; user | CURRENT_USER &#125;] PROCEDURE sp_name ([proc_parameter[,...]]) [characteristic ...] routine_bodyCREATE [DEFINER = &#123; user | CURRENT_USER &#125;] FUNCTION sp_name ([func_parameter[,...]]) RETURNS type [characteristic ...] routine_bodyproc_parameter: [ IN | OUT | INOUT ] param_name typefunc_parameter: param_name typetype: Any valid MySQL data typecharacteristic: COMMENT &apos;string&apos; | LANGUAGE SQL | [NOT] DETERMINISTIC | &#123; CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA &#125; | SQL SECURITY &#123; DEFINER | INVOKER &#125;routine_body: Valid SQL routine statement 存储过程可以加 db_name限定数据库，不加就使用默认数据库 默认情况下，MYSQL给 proc_parameter默认IN，可以选择OUT，INOUT proc_parameter只支持IN characteristic COMMENT用于写备注 LANGUAGE这个server被忽略，只是为了符合SQL标准 DETERMINISTIC和NOT DETERMINISTIC。这个只是创建者自己定义的，MYSQL不会做任何检查。但是如果把NOT DETEMINISTIC定义为DETERMINISTIC，可能导致优化器做出错误的执行计划。相反，把DETEMINISTIC定义为NOT DETERMINISTIC可能让一些可用的优化措施无法使用。如果使用binary logging，需要参考Binary Logging of Stored Programs. { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }这组被server忽略 SQL SECURITY定义谁可以调用。DEFINER表示由DEFINER属性所指定的用户的权限来执行，INVOKER表示以调用这个存储过程的用户的权限来执行。默认DEFINER，且值为CURRENT_USER。如果用户没有过程中需要的权限，那么INVOKER类型过程的就无法调用。 routine_body可以执行Compound-Statement.以及DDL语句，同时存储过程支持事务。 Compiund StatementBEGIN END语法语句块，可嵌套，可结合Lable使用。 Label语法可用于标记BEGIN，LOOP，REPEAT以及WHILE语句。可以用ITERATE和LEAVE指令控制流程。 DECLARE语法声明变量，条件处理或者游标。限制如下： 只能在BEGIN语句中，且必须在最前面 必须按照变量，游标，条件处理的顺序声明。 变量所用DECLARE声明，赋值可以使用SET语法，SELECT ... INTO var_list 或者 FETCH ... INTO var_list 定义格式： DECLARE var_name [, var_name] ... type [DEFAULT value] 控制流程和C语言的类比 MYSQL C 备注 CASE switch IF if LOOP while(1){} 用ITERATE模拟continue，LEAVE模拟break REPATE do…while 用ITERATE模拟continue，LEAVE模拟break WHILE while 用ITERATE模拟continue，LEAVE模拟break 游标游标使用的流程遵循：定义，OPEN，FETCH，CLOSE。语法如下 DECLARE cursor_name CURSOR FOR select_statementOPEN cursor_nameFETCH [[NEXT] FROM] cursor_name INTO var_name [, var_name] ...CLOSE cursor_name 条件处理程序执行过程中可能出现一些需要特殊处理的情况，比如继续执行还是推出程序？可以为一个条件定义处理器，条件也可以被命名。 命名条件使用DECLARE … CONDITION 语法，此步骤可选。 定义处理器使用DECLARE … HANDLER 语法 自己抛出一个条件使用SIGNAL 语法，定义条件处理器中继续抛出使用RESIGNAL 语法 获取错误内容使用 GET DIAGNOSTICS 语法 例子： -- 命名DECLARE division_by_zero CONDITION FOR SQLSTATE &apos;22012&apos;;-- 定义处理器以及使用RESINGAL DECLARE CONTINUE HANDLER FOR division_by_zero RESIGNAL SET MESSAGE_TEXT = &apos;Division by zero / Denominator cannot be zero&apos;; -- GET DIAGNOSTICS语法DROP TABLE test.no_such_table;-- ERROR 1051 (42S02): Unknown table &apos;test.no_such_table&apos;GET DIAGNOSTICS CONDITION 1 @p1 = RETURNED_SQLSTATE, @p2 = MESSAGE_TEXT;SELECT @p1, @p2;+-------+------------------------------------+| @p1 | @p2 |+-------+------------------------------------+| 42S02 | Unknown table &apos;test.no_such_table&apos; |+-------+------------------------------------+ 常用的处理器： 常见问题有许多常见问题是因为MySQL本身的一些限制，可以参考：Restrictions on Stored Programs。下面记录一些常见的或者我碰到的问题，欢迎补充。 FETCH拿不到任何记录如果定义的变量名和SELECT的字段名一样，那么可能出现问题，这是MySQL的一个bug，解决方案是不要使变量名和字段名一样。 ERROR：Cursor declaration after handler declarationDECLARATION定义顺序错误，类似的还有Variable or condition declaration after cursor or handler declaration错误 参考资料https://dev.mysql.com/doc/refman/5.7/en/create-procedure.html http://chuiliu.github.io/2016/02/28/mysql%E7%9A%84definer%E5%92%8Cinvoker/ https://my.oschina.net/u/1424662/blog/485118 https://dev.mysql.com/doc/refman/5.7/en/sql-syntax-compound-statements.html http://www.yiibai.com/mysql/signal-resignal.html http://www.cnblogs.com/langtianya/p/5534222.html https://stackoverflow.com/questions/40661398/mysql-cursor-fetch-null","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"http://yoursite.com/categories/数据库/MySQL/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"一个查询API引发的对前后端职责的思考","slug":"一个查询API引发的对前后端职责的思考","date":"2017-10-21T12:49:56.000Z","updated":"2017-11-03T04:21:37.254Z","comments":true,"path":"2017/10/21/一个查询API引发的对前后端职责的思考/","link":"","permalink":"http://yoursite.com/2017/10/21/一个查询API引发的对前后端职责的思考/","excerpt":"","text":"问题描述有一个在线博客系统，系统提供了一个API，前端只需要传递参数：(开始日期，结束日期)，然后就会返回一个这样的JSON:{日期1:新文章数量,日期2:新文章数量...}。现在来了一个新的需求：用户需要查看当天，本周，本月，最近半年或者一年新发布的文章的数量。现在需要设计后端API供前端调用，那么这个API应该如何设计呢？ 一开始，我想到了3种可能的方案： 直接使用之前的API，前端根据天，周，月等单位换算成时间区间，去后端查询出每天的新文章数量，然后在前端累加。 设计5个API，然后每个API处理不同的单位。 设计一个API，然后有一个枚举类型的参数表示5种不同的情况。 我的第一感觉是：方案1是最简单的，方案2看起来好像也可以，方案3感觉有点复杂了。我到底应该选择哪一种方案呢，每种方案的利弊是什么呢？ 方案一该方案很简单而且看起来很灵活，后端提供一个API，既可以用来获取每天新文章具体数目，又可以用来计算该区间内新总和，那么该方案有什么问题吗？ 我觉得这个方案最大的问题就是暴露了领域知识在前端，这里体现出来的就是前端人员需要计算本周的区间，本月的区间，本年的时间区间。当然这个知识很简单，前端人员肯定都知道怎么换算。但是这确实不应该由前端来处理，为什么呢？ 我个人觉得前端人员的职责主要就是单纯的调用后端的API，然后将数据展示出来。前端人员只需要知道哪些API是来干什么的以及调用的顺序即可。 单位的转换确实应该由后端完成。单位的概念也属于领域的知识，本例子中的年月日比较简单，但如果是(点，刻，字)这种时间单位呢？后端处理数据，数据的单位转换就应当交给后端完成。 举个详细的例子来说明由后端处理的好处：查询2017年9月的新文章数量。如果后端来做2017年9月的查询，那么就有这几种很好的实现： 换算成区间，然后使用之前API的代码查询并对结果求和，之后将结果缓存起来。 后端可以基于时间列创建日期列（如果数据库是MySQL可以使用Virtual columns），然后在日期列上创建索引。甚至查询结果也可以缓存起来。 方案二和方案三方案二和方案三都没有方案一的问题。之所以现在要将这两个放在一起说，是因为这两个的关系有点类似于面向对象设计里面的FlagArgument 问题。其建议不要提供一个唯一的API，然后通过额外的参数表示不同的行为，而是推荐提供多个表示不同行为的API。 Martin Fowler讨论FlagArgument时使用了下面的例子： // 1class Concert... public Booking book (Customer aCustomer, boolean isPremium) &#123;...&#125;//2class Concert... public Booking regularBook(Customer aCustomer) &#123;...&#125; public Booking premiumBook(Customer aCustomer) &#123;...&#125; 他给出了不要使用FlagArgument的主要原因： My reasoning here is that the separate methods communicate more clearly what my intention is when I make the call. Instead of having to remember the meaning of the flag variable when I see book(martin, false) I can easily read regularBook(martin). 从可读性和可维护性说起，假如regularBook的处理逻辑需要修改，那么第二种方式可以更好的定位到所有使用了reqularBook逻辑的地方，第一种方式则比较麻烦。但是这种情况并不是绝对的，在编程语言中的关键字参数或者枚举就可以绕过这个问题: 比如在Python中，我们可以使用关键字参数，调用方式大概如下ins.book(customer,isPremium=True) 使用或者使用枚举:ins.book(customer,PriceType.Premium) 现在讨论其扩展性，假如新增了一种价格类型，第一种方式需要将isPremium变成一个可以表示3种情况的枚举，而第二种方式则需要增加一个API，如果情况很多，那么第二种方式将会有大量的API产生。大量API主要会带来什么问题？我觉得主要看调用该API的人是谁，如果是后端自己用的API那么没什么问题，但是如果要给前端调用就有问题了：假如前端不关心价格类型。 举个例子：如果是第一种方式的API，后端需要告诉告诉前端：Hi Jay，我写了一个预定的API，到时候你传递用户编号和价格类型过来给我就可以了。如果是第二种方式则是：Hi Jay，我写了一系列用于预定的API，所有API你都需要传递用户编号过来，如果是XX价格类型，你就调用XXX API，如果是YY价格类型，你就调用YYY API，如果是…。 如果前端又需要关心价格类型，那么仍然可以采用第一种方式，因为访问后端的API时可以提供命名参数，如：book?price_type=premium。 因此在博客系统案例中，我最终选择了方案三，设计的API如下： GET /recent?range=1mrange值范围：1d 1w 1m 6m 1y... 参考资料https://softwareengineering.stackexchange.com/questions/359452/how-do-i-design-a-backend-api-with-a-different-query-range https://softwareengineering.stackexchange.com/questions/147977/is-it-wrong-to-use-a-boolean-parameter-to-determine-behavior https://martinfowler.com/bliki/FlagArgument.html","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://yoursite.com/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://yoursite.com/tags/软件工程/"},{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"},{"name":"前后端分离","slug":"前后端分离","permalink":"http://yoursite.com/tags/前后端分离/"}]}]}